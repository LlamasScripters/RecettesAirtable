# API Recettes - Serveur Backend

API REST pour la gestion de recettes de cuisine avec intÃ©gration Airtable et IA.

## ğŸš€ DÃ©marrage rapide

### PrÃ©requis

- Docker et Docker Compose
- AccÃ¨s Ã  la base Airtable

### Installation avec Docker (RecommandÃ©)

1. DÃ©marrer tous les services :
```bash
docker compose up -d
```

2. TÃ©lÃ©charger le modÃ¨le IA :
```bash
docker exec -it recettes-ollama ollama pull llama3.2:1b
```

3. L'API sera disponible sur `http://localhost:5000`

### Installation manuelle

1. Installer les dÃ©pendances :
```bash
npm install
```

2. Configurer les variables d'environnement :
CrÃ©er un fichier `.env` avec :

```env
AIRTABLE_API_KEY=
AIRTABLE_BASE_ID=your_base_id
PORT=5000
NODE_ENV=development
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:1b
FRONTEND_URL=http://localhost:3000
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100
```

3. DÃ©marrer le serveur :
```bash
npm run dev
```

## ğŸ“š Documentation API

### Endpoints disponibles

#### Recettes
- `GET /api/recipes` - Lister les recettes avec filtres
- `GET /api/recipes/:id` - RÃ©cupÃ©rer une recette
- `POST /api/recipes/generate` - GÃ©nÃ©rer une recette avec l'IA
- `PUT /api/recipes/:id` - Mettre Ã  jour une recette
- `DELETE /api/recipes/:id` - Supprimer une recette
- `POST /api/recipes/:id/favorite` - Marquer/dÃ©marquer favori
- `POST /api/recipes/analyze-nutrition` - Analyser la nutrition

#### MÃ©tadonnÃ©es
- `GET /api/metadata/allergenes` - Lister les allergÃ¨nes
- `GET /api/metadata/types-plats` - Lister les types de plats
- `GET /api/metadata/ingredients` - Lister les ingrÃ©dients
- `GET /api/metadata/all` - Toutes les mÃ©tadonnÃ©es

#### SystÃ¨me
- `GET /api/health` - VÃ©rifier la santÃ© de l'API
- `GET /` - Informations sur l'API

### ParamÃ¨tres de filtrage (GET /api/recipes)

- `search` - Recherche textuelle dans titre, description, ingrÃ©dients
- `type` - Filtrer par type de plat
- `difficulty` - Filtrer par difficultÃ©
- `allergies` - Exclure les recettes contenant ces allergÃ¨nes (sÃ©parÃ©s par virgule)
- `page` - NumÃ©ro de page (dÃ©faut: 1)
- `limit` - Nombre d'Ã©lÃ©ments par page (dÃ©faut: 10, max: 100)

### Format de rÃ©ponse standard

```json
{
  "success": true,
  "data": {}, 
  "message": "Message de succÃ¨s"
}
```

En cas d'erreur :
```json
{
  "success": false,
  "error": "Message d'erreur"
}
```

### GÃ©nÃ©ration de recette avec IA

POST `/api/recipes/generate`

```json
{
  "ingredients": ["tomate", "basilic", "mozzarella"],
  "servings": 4,
  "allergies": ["gluten"],
  "type": "plat principal",
  "difficulty": "facile"
}
```

## ğŸ—ï¸ Architecture

```
src/
â”œâ”€â”€ config/          # Configuration (Airtable, etc.)
â”œâ”€â”€ controllers/     # ContrÃ´leurs des routes
â”œâ”€â”€ middleware/      # Middlewares (validation, erreurs)
â”œâ”€â”€ routes/          # DÃ©finition des routes
â”œâ”€â”€ services/        # Services (Airtable, IA)
â”œâ”€â”€ types/           # Types TypeScript
â””â”€â”€ index.ts         # Point d'entrÃ©e
```

## ğŸ³ Configuration Docker

L'application utilise Docker Compose avec 3 services :

- `recettes-ollama` : Service IA avec Ollama
- `recettes-server` : API Node.js/Express  
- `recettes-client` : Frontend React/Vite

### Commandes Docker utiles

```bash
# Voir les logs
docker compose logs -f

# RedÃ©marrer un service
docker compose restart server

# ArrÃªter tous les services
docker compose down

# Reconstruire les images
docker compose build
```

## ğŸ”§ Configuration Ollama

Pour utiliser un modÃ¨le diffÃ©rent :

```bash
# TÃ©lÃ©charger un autre modÃ¨le
docker exec -it recettes-ollama ollama pull tinyllama

# Changer le modÃ¨le dans compose.yml
OLLAMA_MODEL=tinyllama
```

## ğŸ›¡ï¸ SÃ©curitÃ©

- Rate limiting : 100 requÃªtes par 15 minutes
- CORS configurÃ© pour le frontend
- Helmet pour les headers de sÃ©curitÃ©
- Validation des donnÃ©es d'entrÃ©e avec Zod
- Gestion d'erreurs sÃ©curisÃ©e

## ğŸ› DÃ©bogage

Les logs incluent :
- RequÃªtes HTTP (morgan)
- Erreurs serveur dÃ©taillÃ©es en dÃ©veloppement
- Informations de dÃ©marrage

Pour dÃ©boguer :
1. VÃ©rifier que les variables d'environnement sont correctes
2. Tester la connexion Airtable
3. VÃ©rifier que Ollama fonctionne
4. Consulter les logs du serveur

## ğŸ“ Scripts disponibles

- `npm run dev` - DÃ©marrage en mode dÃ©veloppement
- `npm run build` - Compilation TypeScript
- `npm start` - DÃ©marrage en production
- `npm test` - Lancer les tests

## âš¡ Performance

- Compression gzip activÃ©e
- Limitation de taille des requÃªtes : 10MB
- Pagination des rÃ©sultats
- Cache potentiel via proxy (recommandÃ© pour la production) 